---
tags:
- sentence-transformers
- sentence-similarity
- feature-extraction
- dense
- generated_from_trainer
- dataset_size:2284
- loss:MultipleNegativesRankingLoss
base_model: BAAI/bge-small-en
widget:
- source_sentence: What specific topics are covered in the course on Data Science
    for Healthcare within the DSI program at UChicago?
  sentences:
  - 'Title: Online Program - DSI


    Content: r science, data visualization shows you how to better understand the
    data, present clear evidence of your findings to your intended audience and tell
    engaging data stories through charts and graphics. This course is designed to
    introduce data visualization as a medium of effective communication using strategic
    storytelling, and the basis for interactive information dashboards.


    Digital Marketing Analytics in Theory and Practice Successfully marketing brands
    today requires a well-balanced blend of art and science. This course introduces
    students to the science of web analytics while casting a keen eye toward the artful
    use of numbers found in the digital space. The goal is to provide marketers with
    the foundation needed to apply data analytics to real-world challenges they confront
    daily in their professional lives.'
  - 'Title: Online Program - DSI


    Content: annel marketing effectiveness and ROI. The course will use a combination
    of lecture, in-class discussions, group assignments, and a final group project.
    The course lays special emphasis on algorithms. Hence it draws heavily from the
    fields of optimization, machine-learning based recommendation systems, association
    rules, consumer choice models, Bayesian estimation, experimentation and analysis
    of covariance, advanced visualization techniques for mapping brand perceptions,
    and analysis of social media data using advanced NLP techniques. Data Science
    for Healthcare Given the breadth of the field of health analytics, this course
    will provide an overview of the development and rapid expansion of analytics in
    healthcare, major and emerging topical areas, and current issues related to research
    methods to improve human health.'
  - 'Title: In-Person Program - DSI


    Content: d we will cover the most popular approaches.


    Data Engineering Platforms teaches effective data engineering‚Äîan essential first
    step in building an analytics-driven competitive advantage in the market.


    Big Data and Cloud Computing teaches students how to approach big data and large-scale
    machine learning applications. There is no single definition of big data and multiple
    emerging software packages exist to work with it, and we will cover the most popular
    approaches.


    Leadership and Consulting for Data Science The Leadership and Consulting for Data
    Scientist course is focused on: ‚Ä¢ Learning techniques and proven methods to effectively
    grasp the business domain including organizational dynamics of consultancies and
    client organizations ‚Ä¢ Developing relevant solutions to enterprise problems using
    the sampling methods, traditional statistical techniques and modern machine learning
    models that deliver value to the organization ‚Ä¢ Practicing successful project
    delivery through effective data'
- source_sentence: What specific AI/ML capabilities did Nick Kadochnikov develop at
    William Blair in his role as Director of AI?
  sentences:
  - 'Title: Nick Kadochnikov - DSI


    Content: ons. These innovative capabilities assist law firms and corporate legal
    teams in enhancing their service quality, making legal processes more streamlined,
    accessible, and requiring less manual effort.


    Before joining Harbor, Nick served as a Director of AI at William Blair, where
    he oversaw the development of advanced AI/ML capabilities and intelligent workflows
    to transform Investment Banking processes. Prior to that, Nick dedicated 20 years
    at IBM, successfully crafting AI solutions for a wide range of enterprise functions
    such as supply-chain, sales, marketing, finance, procurement, and legal. In his
    final role at IBM Watson Health Consulting, his main focus was on utilizing AI
    to address healthcare challenges, enhancing patient outcomes, elevating population
    health, and optimizing the efficiency of clinical trials.'
  - 'Title: Greg Green - DSI


    Content: ched since joining the University of Chicago include an innovative approach
    to ‚ÄúLeadership in Data Science and Artificial Intelligence‚Äù, ‚ÄúConsulting in Data
    Science‚Äù and ‚ÄúYour Career in Data Science‚Äù.


    Throughout his professional career, Greg has used his expertise in digital strategies,
    business analytics, and new product development to drive rapid revenue growth
    and accelerate business transformation. His previous work bringing innovation
    to an academic environment included authoring a Marketing Analytics course, designing
    a pre-requisite applied statistics course and serving as a lecturer for Marketing
    Analytics at Northwestern University.


    Greg‚Äôs industry roles include Chief Analytics Officer at Harland Clarke Holdings,
    Director at Google, EVP/Managing Director at Publicis Groupe, and Analytics Practice
    Lead at PwC. Greg‚Äôs patented cloud-based media analytics platform was highlighted
    in Harvard Business Review and Fast Company.'
  - 'Title: Online Program - DSI


    Content: rter. This course provides general exposure to basic statistical concepts
    that are necessary for students to understand the content presented in more advanced
    courses in the program. 0 units, no cost.


    This Foundational, optional course is held in the 5 weeks leading up to the start
    of your first quarter. This course provides general exposure to basic statistical
    concepts that are necessary for students to understand the content presented in
    more advanced courses in the program. 0 units, no cost.


    R for Data Science (Foundational, optional) This Foundational, optional course
    is held in the 5 weeks leading up to the start of your first quarter. This course
    is an introduction to the essential concepts and techniques for the statistical
    computing language R. 0 units, no cost.'
- source_sentence: '- Can you provide more details about the interactive sessions
    and industry solutions development in the DSI program?'
  sentences:
  - 'Title: Course Progressions - DSI


    Content: y‚Äôs business settings.


    Time Series Analysis is a science as well as the art of making rational predictions
    based on previous records. It is widely used in various fields in today‚Äôs business
    settings.


    Elective 1 Letter Grade Elective offerings vary. Students will work with their
    academic advisor to select electives based on their interests and course availability.
    Past electives include: Generative AI Principles, Advanced Computer Vision with
    Deep Learning, Advanced Machine Learning and Artificial Intelligence, Bayesian
    Machine Learning with GenAI Applications, Data Science for Algorithmic Marketing,
    Data Visualization Techniques, Digital Marketing Analytics in Theory and Practice,
    Financial Analytics, Health Analytics, Machine Learning Operations, Natural Language
    Processing and Cognitive Computing, Real Time Intelligent Systems, Reinforcement
    Learning, Supply Chain Optimization.'
  - 'Title: Online Program - DSI


    Content: roblems such as Computer Vision and Natural Language Processing (NLP)
    and has had a massive impact on various industries such as healthcare, retail,
    automotive, industrial automation, and agriculture. This course will enable students
    to build Deep Learning models and apply them to computer vision tasks such as
    object recognition, detection, and segmentation. Students will gain an in-depth
    understanding of the Deep Learning model development process, tools, and frameworks.
    Although the focus of the course will primarily be computer vision, students will
    work on both image and nonimage datasets during class exercises and assignments.
    Students will gain hands-on experience in popular libraries such as Tensorflow,
    Keras, and PyTorch. Students will also learn to apply state of the art models
    such as ResNet, EfficientNet, RCNNs, YOLO, Vision Transformers, etc. for computer
    vision and work on datasets such as CIFAR, ImageNet, MS COCO, and MPII Human Poses.'
  - 'Title: Online Program - DSI


    Content: opportunity to


    Network with industry leaders and alumni


    Meet a vibrant and supportive community of like-minded students and faculty


    Get to know, bond, and network with peers from across the country


    Participate in interactive sessions, working to develop industry solutions


    Gain career insights and discuss the latest trends and challenges in AI/ML


    Hear from students about their experience in Capstone Projects


    Tour the Data Science Institute


    Future Immersion Weekend dates are:


    Autumn 2026


    We look forward to seeing you at the event!


    #### Note for International Students'
- source_sentence: What specific experiences and expertise does Don have that make
    him a valuable faculty member for the MS in Business Analytics program at DePaul
    University?
  sentences:
  - 'Title: Faculty, Instructors, Staff - DSI


    Content: sity of Chicago. Previously Don served as Board President of Chicago
    Chapter of the American Statistical Association and as Program Director of the
    MS, Business Analytics program at DePaul University. As Senior VP, Analytics for
    HAVI Group, Don helped pioneer new analytics implementations for McDonald‚Äôs and
    Coca-Cola. Prior to joining HAVI Group, Don was Director of Advertising Analytics
    for Sears, Roebuck & Co. ‚Äì bringing cutting edge analytics of Sears‚Äô media (tv,
    radio, print) support to drive ROI based decision making. Don has also managed
    research and analytics for several major brands for Kraft Foods and site location
    analytics and modeling for Hallmark Cards.'
  - 'Title: DSI Postdoctoral Scholars - DSI


    Content: s for a UChicago faculty member to indicate that they would be willing
    to work with you should you be admitted to the program. A brief template for the
    letter is provided on the InfoReady application.


    You are not required to submit a letter of collaboration from a UChicago faculty
    member, however you are welcome to if you would like. The purpose of a letter
    of collaboration is for a UChicago faculty member to indicate that they would
    be willing to work with you should you be admitted to the program. A brief template
    for the letter is provided on the InfoReady application.


    Are international applicants eligible to apply? Yes, international applicants
    are eligible to apply.


    Yes, international applicants are eligible to apply.'
  - 'Title: Events & Deadlines - DSI


    Content: lication Deadline 2-year Thesis Track (21 months; 18 courses)*


    Scholarship Priority Deadline 1-year (12-15 months; 12 courses)


    Final Application Deadline 2-year Thesis Track (21 months; 18 courses)*


    January 26, 2026 ‚Äì International Application Deadline (requiring visa sponsorship
    from UChicago)


    March 4, 2026 ‚Äì Second Priority Application Deadline


    May 6, 2026 ‚Äì Third Priority Application Deadline


    June 23, 2026 ‚Äì Final Application Deadline


    Online:


    Autumn 2026 December 4, 2025 ‚Äì Scholarship Priority Deadline June 23, 2026 ‚Äì Final
    Application Deadline


    December 4, 2025 ‚Äì Scholarship Priority Deadline


    Online application decisions are released on a rolling basis. The deadline represents
    the last date applications are accepted for the respective start date.


    *The application portal may close early if the cohort is filled.'
- source_sentence: What kind of real-world applications have UChicago Applied Data
    Science Capstone projects focused on?
  sentences:
  - 'Title: 2025 Research Day Highlights Growth with Global Impact - DSI


    Content: ipitated a revolution in weather forecasting by making weather simulations
    faster, lower cost, and more accurate than ever, enabling earlier event prediction
    and expanding access to millions globally.


    As one example, in the past year, the AICE team has partnered with the Indian
    government to share AI-supported forecasts with 50 million Indian farmers on a
    weekly basis via text message. In an environment where monsoons can upend a season‚Äôs
    worth of cultivation (and livelihood), better forecasts could empower farmers
    to make cultivation choices that work with the weather rather than against it.
    Through a collaboration with the Gates Foundation and the government of the United
    Arab Emirates, the AICE team plans to further democratize forecast access over
    the next three years by training government forecasters across 30 low- and middle-income
    countries.'
  - 'Title: DSI Postdoctoral Scholars - DSI


    Content: advance research innovation in interdisciplinary or foundational approaches
    in data science, or real world challenges.


    For questions about this application, please contact data-science@uchicago.edu.


    Program Structure & Benefits What you‚Äôll do: Independent Research: Scholars will
    have the freedom to pursue their own research interests with a majority of their
    time spent working on scholar-driven research projects and no teaching responsibilities.
    Joint Research with Mentor: Scholars will help lead and execute collaborative
    work on cutting-edge research projects with mentors in their academic field and
    area of interest. Professional Development: Scholars will gain training and experience
    with: required mentoring and outreach through our Summer Lab and Clinic programs
    (required three quarters annually); communicating your research to a broad audience;
    engaging with the media and external stakeholders; and applying for and securing
    funding.'
  - 'Title: Capstone Projects - DSI


    Content: step neural network to examine images of yoga poses and recognize the
    poses in order to provide feedback to the app‚Äôs yoga-practicing user.


    ### Using Image Recognition to Measure the Speed of a Pitch


    One UChicago Applied Data Science Capstone team developed an app that applied
    image recognition algorithms to measure the speed of a pitched baseball. Their
    ace app captured video, isolated the pitched ball, calculated the velocity of
    the pitch, and displayed this measurement so that users would be able to measure
    the speed of a pitch with their smartphones.


    ### Real-Time Credit Card Fraud Detection


    Credit card fraud puts consumers‚Äô identities at risk while credit card providers
    are forced to cover fraudulent charges. A team of Applied Data Science students
    carefully studied this problem ‚Äì they created synthetic data that represented
    a large population of credit card users and built a model that catches credit
    card fraud in real time.


    ## Interested in Becoming a Capstone Sponsor?'
pipeline_tag: sentence-similarity
library_name: sentence-transformers
metrics:
- cosine_accuracy@1
- cosine_accuracy@3
- cosine_accuracy@5
- cosine_accuracy@10
- cosine_precision@1
- cosine_precision@3
- cosine_precision@5
- cosine_precision@10
- cosine_recall@1
- cosine_recall@3
- cosine_recall@5
- cosine_recall@10
- cosine_ndcg@10
- cosine_mrr@10
- cosine_map@100
model-index:
- name: SentenceTransformer based on BAAI/bge-small-en
  results:
  - task:
      type: information-retrieval
      name: Information Retrieval
    dataset:
      name: validation
      type: validation
    metrics:
    - type: cosine_accuracy@1
      value: 0.5262237762237763
      name: Cosine Accuracy@1
    - type: cosine_accuracy@3
      value: 0.8234265734265734
      name: Cosine Accuracy@3
    - type: cosine_accuracy@5
      value: 0.9213286713286714
      name: Cosine Accuracy@5
    - type: cosine_accuracy@10
      value: 0.9877622377622378
      name: Cosine Accuracy@10
    - type: cosine_precision@1
      value: 0.5262237762237763
      name: Cosine Precision@1
    - type: cosine_precision@3
      value: 0.2744755244755245
      name: Cosine Precision@3
    - type: cosine_precision@5
      value: 0.18426573426573423
      name: Cosine Precision@5
    - type: cosine_precision@10
      value: 0.09877622377622376
      name: Cosine Precision@10
    - type: cosine_recall@1
      value: 0.5262237762237763
      name: Cosine Recall@1
    - type: cosine_recall@3
      value: 0.8234265734265734
      name: Cosine Recall@3
    - type: cosine_recall@5
      value: 0.9213286713286714
      name: Cosine Recall@5
    - type: cosine_recall@10
      value: 0.9877622377622378
      name: Cosine Recall@10
    - type: cosine_ndcg@10
      value: 0.7637704048338626
      name: Cosine Ndcg@10
    - type: cosine_mrr@10
      value: 0.6908626096126096
      name: Cosine Mrr@10
    - type: cosine_map@100
      value: 0.6913793046026951
      name: Cosine Map@100
---

# SentenceTransformer based on BAAI/bge-small-en

This is a [sentence-transformers](https://www.SBERT.net) model finetuned from [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en). It maps sentences & paragraphs to a 384-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
- **Base model:** [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en) <!-- at revision 2275a7bdee235e9b4f01fa73aa60d3311983cfea -->
- **Maximum Sequence Length:** 512 tokens
- **Output Dimensionality:** 384 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Training Dataset:** Unknown -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/huggingface/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the ü§ó Hub
model = SentenceTransformer("sentence_transformers_model_id")
# Run inference
sentences = [
    'What kind of real-world applications have UChicago Applied Data Science Capstone projects focused on?',
    'Title: Capstone Projects - DSI\n\nContent: step neural network to examine images of yoga poses and recognize the poses in order to provide feedback to the app‚Äôs yoga-practicing user.\n\n### Using Image Recognition to Measure the Speed of a Pitch\n\nOne UChicago Applied Data Science Capstone team developed an app that applied image recognition algorithms to measure the speed of a pitched baseball. Their ace app captured video, isolated the pitched ball, calculated the velocity of the pitch, and displayed this measurement so that users would be able to measure the speed of a pitch with their smartphones.\n\n### Real-Time Credit Card Fraud Detection\n\nCredit card fraud puts consumers‚Äô identities at risk while credit card providers are forced to cover fraudulent charges. A team of Applied Data Science students carefully studied this problem ‚Äì they created synthetic data that represented a large population of credit card users and built a model that catches credit card fraud in real time.\n\n## Interested in Becoming a Capstone Sponsor?',
    'Title: DSI Postdoctoral Scholars - DSI\n\nContent: advance research innovation in interdisciplinary or foundational approaches in data science, or real world challenges.\n\nFor questions about this application, please contact data-science@uchicago.edu.\n\nProgram Structure & Benefits What you‚Äôll do: Independent Research: Scholars will have the freedom to pursue their own research interests with a majority of their time spent working on scholar-driven research projects and no teaching responsibilities. Joint Research with Mentor: Scholars will help lead and execute collaborative work on cutting-edge research projects with mentors in their academic field and area of interest. Professional Development: Scholars will gain training and experience with: required mentoring and outreach through our Summer Lab and Clinic programs (required three quarters annually); communicating your research to a broad audience; engaging with the media and external stakeholders; and applying for and securing funding.',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 384]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities)
# tensor([[1.0000, 0.6321, 0.0747],
#         [0.6321, 1.0000, 0.1071],
#         [0.0747, 0.1071, 1.0000]])
```

<!--
### Direct Usage (Transformers)

<details><summary>Click to see the direct usage in Transformers</summary>

</details>
-->

<!--
### Downstream Usage (Sentence Transformers)

You can finetune this model on your own dataset.

<details><summary>Click to expand</summary>

</details>
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

## Evaluation

### Metrics

#### Information Retrieval

* Dataset: `validation`
* Evaluated with [<code>InformationRetrievalEvaluator</code>](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#sentence_transformers.evaluation.InformationRetrievalEvaluator)

| Metric              | Value      |
|:--------------------|:-----------|
| cosine_accuracy@1   | 0.5262     |
| cosine_accuracy@3   | 0.8234     |
| cosine_accuracy@5   | 0.9213     |
| cosine_accuracy@10  | 0.9878     |
| cosine_precision@1  | 0.5262     |
| cosine_precision@3  | 0.2745     |
| cosine_precision@5  | 0.1843     |
| cosine_precision@10 | 0.0988     |
| cosine_recall@1     | 0.5262     |
| cosine_recall@3     | 0.8234     |
| cosine_recall@5     | 0.9213     |
| cosine_recall@10    | 0.9878     |
| **cosine_ndcg@10**  | **0.7638** |
| cosine_mrr@10       | 0.6909     |
| cosine_map@100      | 0.6914     |

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Dataset

#### Unnamed Dataset

* Size: 2,284 training samples
* Columns: <code>sentence_0</code> and <code>sentence_1</code>
* Approximate statistics based on the first 1000 samples:
  |         | sentence_0                                                                         | sentence_1                                                                           |
  |:--------|:-----------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------|
  | type    | string                                                                             | string                                                                               |
  | details | <ul><li>min: 12 tokens</li><li>mean: 24.69 tokens</li><li>max: 47 tokens</li></ul> | <ul><li>min: 26 tokens</li><li>mean: 166.76 tokens</li><li>max: 263 tokens</li></ul> |
* Samples:
  | sentence_0                                                                                                                                                                           | sentence_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
  |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | <code>How does the elective course in Supply Chain Optimization address challenges related to the exponential growth of "Big Data" in large-scale transactional environments?</code> | <code>Title: In-Person Program - DSI<br><br>Content: ct based and will focus on developing end-to-end analytical solutions in the following areas: Finance and trading, blockchains and crypto-currencies, image recognition, and video surveillance systems.<br><br>Supply Chain Optimization ‚ÄúBig Data‚Äù continues to grow exponentially in our large-scale transactional world where 100,000s of SKUs and millions of customers are interacting with 1:1 offers that include differential pricing, shipping timing/costs and even made to order ‚Äúcustom‚Äù product configurations. These consumer behaviors are quickly advancing the availability of new data and techniques within the discipline of Data Science. This elective course will give students the opportunity to apply their skills in data visualization, data mining tools, predictive modeling, and advanced optimization techniques to address Supply Chain challenges.</code> |
  | <code>- How long has Shaddy Abado been instructing graduate-level courses and in what types of academic programs?</code>                                                             | <code>Title: Shaddy Abado, PhD - DSI<br><br>Content: ## Share<br><br>Email page on Facebook (opens new window)<br><br>Share page on X (opens new window)<br><br>Email Page (opens new window)<br><br>Shaddy Abado is a Lead Data Scientist at Ulta Beauty, where he focuses on developing machine learning models to optimize marketing strategies and enhance personalized experiences. With a background in engineering, throughout his career, Shaddy‚Äôs interests span various fields ranging from researching light-fluid interactions for aero-optics applications, developing data driven solutions for equipment predictive maintenance, and consulting companies throughout their digital transformation. Shaddy is passionate about teaching and engaging students in insightful education. Since 2012, he has been instructing graduate-level courses in various academic programs.</code>                                              |
  | <code>What methods and techniques are taught in the DSI program for analyzing social media data?</code>                                                                              | <code>Title: Online Program - DSI<br><br>Content: dels, Bayesian estimation, experimentation and analysis of covariance, advanced visualization techniques for mapping brand perceptions, and analysis of social media data using advanced NLP techniques.<br><br>This course focuses on marketing science methods and algorithms for undertaking competitive analysis in the digital landscape: market segmentation, mining databases for effective digital marketing, design of new digital and traditional products, forecasting sales and product diffusion, real time product positioning, intra omni-channel optimization and inter omni-channel resource allocation, and pricing across both omni-channel marketing effectiveness and ROI. The course will use a combination of lecture, in-class discussions, group assignments, and a final group project. The course lays special emphasis on algorithms.</code>                        |
* Loss: [<code>MultipleNegativesRankingLoss</code>](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss) with these parameters:
  ```json
  {
      "scale": 20.0,
      "similarity_fct": "cos_sim",
      "gather_across_devices": false
  }
  ```

### Training Hyperparameters
#### Non-Default Hyperparameters

- `eval_strategy`: steps
- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `multi_dataset_batch_sampler`: round_robin

#### All Hyperparameters
<details><summary>Click to expand</summary>

- `overwrite_output_dir`: False
- `do_predict`: False
- `eval_strategy`: steps
- `prediction_loss_only`: True
- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `per_gpu_train_batch_size`: None
- `per_gpu_eval_batch_size`: None
- `gradient_accumulation_steps`: 1
- `eval_accumulation_steps`: None
- `torch_empty_cache_steps`: None
- `learning_rate`: 5e-05
- `weight_decay`: 0.0
- `adam_beta1`: 0.9
- `adam_beta2`: 0.999
- `adam_epsilon`: 1e-08
- `max_grad_norm`: 1
- `num_train_epochs`: 3
- `max_steps`: -1
- `lr_scheduler_type`: linear
- `lr_scheduler_kwargs`: {}
- `warmup_ratio`: 0.0
- `warmup_steps`: 0
- `log_level`: passive
- `log_level_replica`: warning
- `log_on_each_node`: True
- `logging_nan_inf_filter`: True
- `save_safetensors`: True
- `save_on_each_node`: False
- `save_only_model`: False
- `restore_callback_states_from_checkpoint`: False
- `no_cuda`: False
- `use_cpu`: False
- `use_mps_device`: False
- `seed`: 42
- `data_seed`: None
- `jit_mode_eval`: False
- `bf16`: False
- `fp16`: False
- `fp16_opt_level`: O1
- `half_precision_backend`: auto
- `bf16_full_eval`: False
- `fp16_full_eval`: False
- `tf32`: None
- `local_rank`: 0
- `ddp_backend`: None
- `tpu_num_cores`: None
- `tpu_metrics_debug`: False
- `debug`: []
- `dataloader_drop_last`: False
- `dataloader_num_workers`: 0
- `dataloader_prefetch_factor`: None
- `past_index`: -1
- `disable_tqdm`: False
- `remove_unused_columns`: True
- `label_names`: None
- `load_best_model_at_end`: False
- `ignore_data_skip`: False
- `fsdp`: []
- `fsdp_min_num_params`: 0
- `fsdp_config`: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
- `fsdp_transformer_layer_cls_to_wrap`: None
- `accelerator_config`: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
- `parallelism_config`: None
- `deepspeed`: None
- `label_smoothing_factor`: 0.0
- `optim`: adamw_torch
- `optim_args`: None
- `adafactor`: False
- `group_by_length`: False
- `length_column_name`: length
- `project`: huggingface
- `trackio_space_id`: trackio
- `ddp_find_unused_parameters`: None
- `ddp_bucket_cap_mb`: None
- `ddp_broadcast_buffers`: False
- `dataloader_pin_memory`: True
- `dataloader_persistent_workers`: False
- `skip_memory_metrics`: True
- `use_legacy_prediction_loop`: False
- `push_to_hub`: False
- `resume_from_checkpoint`: None
- `hub_model_id`: None
- `hub_strategy`: every_save
- `hub_private_repo`: None
- `hub_always_push`: False
- `hub_revision`: None
- `gradient_checkpointing`: False
- `gradient_checkpointing_kwargs`: None
- `include_inputs_for_metrics`: False
- `include_for_metrics`: []
- `eval_do_concat_batches`: True
- `fp16_backend`: auto
- `push_to_hub_model_id`: None
- `push_to_hub_organization`: None
- `mp_parameters`: 
- `auto_find_batch_size`: False
- `full_determinism`: False
- `torchdynamo`: None
- `ray_scope`: last
- `ddp_timeout`: 1800
- `torch_compile`: False
- `torch_compile_backend`: None
- `torch_compile_mode`: None
- `include_tokens_per_second`: False
- `include_num_input_tokens_seen`: no
- `neftune_noise_alpha`: None
- `optim_target_modules`: None
- `batch_eval_metrics`: False
- `eval_on_start`: False
- `use_liger_kernel`: False
- `liger_kernel_config`: None
- `eval_use_gather_object`: False
- `average_tokens_across_devices`: True
- `prompts`: None
- `batch_sampler`: batch_sampler
- `multi_dataset_batch_sampler`: round_robin
- `router_mapping`: {}
- `learning_rate_mapping`: {}

</details>

### Training Logs
| Epoch  | Step | validation_cosine_ndcg@10 |
|:------:|:----:|:-------------------------:|
| 0.3497 | 50   | 0.7122                    |
| 0.6993 | 100  | 0.7420                    |
| 1.0    | 143  | 0.7545                    |
| 1.0490 | 150  | 0.7531                    |
| 1.3986 | 200  | 0.7493                    |
| 1.7483 | 250  | 0.7540                    |
| 2.0    | 286  | 0.7628                    |
| 2.0979 | 300  | 0.7592                    |
| 2.4476 | 350  | 0.7621                    |
| 2.7972 | 400  | 0.7638                    |


### Framework Versions
- Python: 3.10.18
- Sentence Transformers: 5.1.2
- Transformers: 4.57.1
- PyTorch: 2.2.2
- Accelerate: 1.11.0
- Datasets: 4.4.1
- Tokenizers: 0.22.1

## Citation

### BibTeX

#### Sentence Transformers
```bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
```

#### MultipleNegativesRankingLoss
```bibtex
@misc{henderson2017efficient,
    title={Efficient Natural Language Response Suggestion for Smart Reply},
    author={Matthew Henderson and Rami Al-Rfou and Brian Strope and Yun-hsuan Sung and Laszlo Lukacs and Ruiqi Guo and Sanjiv Kumar and Balint Miklos and Ray Kurzweil},
    year={2017},
    eprint={1705.00652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->